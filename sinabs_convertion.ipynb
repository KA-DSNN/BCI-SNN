{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "import numpy as np\n",
    "import numpy.matlib as npm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers\n",
    "from keras.losses import categorical_crossentropy\n",
    "\n",
    "from bcilib.ssvep_utils_pytorch import CNN, RasterizeSlice, CustomTensorDataset\n",
    "from bcilib import ssvep_utils as su \n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from snnlib import snn_utils\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (8, 220, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(features_data):\n",
    "    features_data = np.reshape(features_data, (features_data.shape[0], features_data.shape[1], \n",
    "                                               features_data.shape[2], \n",
    "                                               features_data.shape[3]*features_data.shape[4]))\n",
    "    train_data = features_data[:, :, 0, :].T\n",
    "    for target in range(1, features_data.shape[2]):\n",
    "        train_data = np.vstack([train_data, np.squeeze(features_data[:, :, target, :]).T])\n",
    "\n",
    "    train_data = np.reshape(train_data, (train_data.shape[0], train_data.shape[1], \n",
    "                                         train_data.shape[2], 1))\n",
    "    total_epochs_per_class = features_data.shape[3]\n",
    "    features_data = []\n",
    "    class_labels = np.arange(CNN_PARAMS['num_classes'])\n",
    "    labels = (npm.repmat(class_labels, total_epochs_per_class, 1).T).ravel()\n",
    "    labels = to_categorical(labels)\n",
    "    \n",
    "    return train_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.abspath('data/second_change')\n",
    "\n",
    "CNN_PARAMS = {\n",
    "    'batch_size': 64,\n",
    "    'epochs': 50,\n",
    "    'droprate': 0.25,\n",
    "    'learning_rate': 0.001,\n",
    "    'lr_decay': 0.0,\n",
    "    'l2_lambda': 0.0001,\n",
    "    'momentum': 0.9,\n",
    "    'kernel_f': 10,\n",
    "    'n_ch': 8,\n",
    "    'num_classes': 12}\n",
    "\n",
    "FFT_PARAMS = {\n",
    "    'resolution': 0.2930,\n",
    "    'start_frequency': 3.0,\n",
    "    'end_frequency': 35.0,\n",
    "    'sampling_rate': 256\n",
    "}\n",
    "\n",
    "window_len = 1\n",
    "shift_len = 1\n",
    "    \n",
    "all_acc = np.zeros((10, 1))\n",
    "\n",
    "magnitude_spectrum_features = dict()\n",
    "complex_spectrum_features = dict()\n",
    "\n",
    "mcnn_training_data = dict()\n",
    "ccnn_training_data = dict()\n",
    "\n",
    "mcnn_results = dict()\n",
    "ccnn_results = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_segmented_data = dict()\n",
    "for subject in range(0, 10):\n",
    "    dataset = sio.loadmat(f'{data_path}/s{subject+1}.mat')\n",
    "    eeg = np.array(dataset['eeg'], dtype='float32')\n",
    "    \n",
    "    CNN_PARAMS['num_classes'] = eeg.shape[0]\n",
    "    CNN_PARAMS['n_ch'] = eeg.shape[1]\n",
    "    total_trial_len = eeg.shape[2]\n",
    "    num_trials = eeg.shape[3]\n",
    "    sample_rate = 256\n",
    "\n",
    "    filtered_data = su.get_filtered_eeg(eeg, 6, 80, 4, sample_rate)\n",
    "    all_segmented_data[f's{subject+1}'] = su.get_segmented_epochs(filtered_data, window_len, \n",
    "                                                                  shift_len, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in all_segmented_data.keys():\n",
    "    complex_spectrum_features[subject] = su.complex_spectrum_features(all_segmented_data[subject], \n",
    "                                                                      FFT_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in all_segmented_data.keys():\n",
    "#    mcnn_training_data[subject] = dict()\n",
    "    ccnn_training_data[subject] = dict()\n",
    "#     train_data, labels = get_training_data(magnitude_spectrum_features[subject])\n",
    "#     mcnn_training_data[subject]['train_data'] = train_data\n",
    "#     mcnn_training_data[subject]['label'] = labels\n",
    "    \n",
    "    train_data, labels = get_training_data(complex_spectrum_features[subject])\n",
    "    train_data[train_data < 0] = 0.\n",
    "    ccnn_training_data[subject]['train_data'] = train_data\n",
    "    ccnn_training_data[subject]['label'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_loader, num_batches=None):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    batch_count = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Iterate over data\n",
    "        pbar = tqdm.notebook.tqdm(data_loader)\n",
    "        for data, target in pbar:\n",
    "            #if data_loader.dataset.spiking:\n",
    "            if data_loader.dataset:\n",
    "                if len(data.size()) > 4:\n",
    "                    warnings.warn(\"Warning: Batch size needs to be 1, only first sample used.\", stacklevel=2)\n",
    "                    data = data[0]\n",
    "                    target = target[0]\n",
    "            output = model(data)\n",
    "            #print(output)\n",
    "            #if data_loader.dataset.spiking:\n",
    "            if data_loader.dataset:\n",
    "                output = output.sum(0).squeeze().unsqueeze(0)\n",
    "                target = target.unsqueeze(0)\n",
    "            \n",
    "            # get the index of the max log-probability\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            # Compute the total correct predictions\n",
    "            correct += target[0][pred.item()].item() == 1\n",
    "            \n",
    "            batch_count += 1\n",
    "            if (batch_count*data_loader.batch_size)%500 == 0:\n",
    "                pbar.set_postfix({\"Accuracy\" : correct/(batch_count*data_loader.batch_size)})\n",
    "            if num_batches:\n",
    "                if num_batches <= batch_count: break;\n",
    "\n",
    "    # Total samples:\n",
    "    num_data = (batch_count*data_loader.batch_size)\n",
    "\n",
    "    print(f'Test set: Accuracy: {correct}/{num_data} ({100. * correct / num_data}%)\\n'.format(correct, num_data,\n",
    "        ))\n",
    "    return correct / num_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lam: 1 | Div: 12\n",
      "\n",
      "C-SCNN - Subject: s1\n",
      "INPUT SHAPE:  torch.Size([720, 8, 220, 1])\n",
      "LABEL SHAPE:  torch.Size([720, 12])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94af16c8f5484987944c0d52ae9673c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=144.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 71/144 (49.30555555555556%)\n",
      "\n",
      "\n",
      "C-SCNN - Subject: s2\n",
      "INPUT SHAPE:  torch.Size([720, 8, 220, 1])\n",
      "LABEL SHAPE:  torch.Size([720, 12])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9325fff6974c4da68d924bd9f49c4a4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=144.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 27/144 (18.75%)\n",
      "\n",
      "\n",
      "C-SCNN - Subject: s3\n",
      "INPUT SHAPE:  torch.Size([720, 8, 220, 1])\n",
      "LABEL SHAPE:  torch.Size([720, 12])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b0effa3af144dd8b522b44c0f7e9aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=144.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 108/144 (75.0%)\n",
      "\n",
      "\n",
      "C-SCNN - Subject: s4\n",
      "INPUT SHAPE:  torch.Size([720, 8, 220, 1])\n",
      "LABEL SHAPE:  torch.Size([720, 12])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f1c2a423f84053a93d63047d129cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=144.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 128/144 (88.88888888888889%)\n",
      "\n",
      "\n",
      "C-SCNN - Subject: s5\n",
      "INPUT SHAPE:  torch.Size([720, 8, 220, 1])\n",
      "LABEL SHAPE:  torch.Size([720, 12])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16568e27153a4f07ba1d7cd3d4e12ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=144.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 129/144 (89.58333333333333%)\n",
      "\n",
      "\n",
      "C-SCNN - Subject: s6\n",
      "INPUT SHAPE:  torch.Size([720, 8, 220, 1])\n",
      "LABEL SHAPE:  torch.Size([720, 12])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3872ab34ad0a43adb23d54cdab47ce2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=144.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 131/144 (90.97222222222223%)\n",
      "\n",
      "\n",
      "C-SCNN - Subject: s7\n",
      "INPUT SHAPE:  torch.Size([720, 8, 220, 1])\n",
      "LABEL SHAPE:  torch.Size([720, 12])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca97c3f3ece4984b4f70e8bae81f999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=144.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 95/144 (65.97222222222223%)\n",
      "\n",
      "\n",
      "C-SCNN - Subject: s8\n",
      "INPUT SHAPE:  torch.Size([720, 8, 220, 1])\n",
      "LABEL SHAPE:  torch.Size([720, 12])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050f3f1a7b324510ab50ea6e0491b8b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=144.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 142/144 (98.61111111111111%)\n",
      "\n",
      "\n",
      "C-SCNN - Subject: s9\n",
      "INPUT SHAPE:  torch.Size([720, 8, 220, 1])\n",
      "LABEL SHAPE:  torch.Size([720, 12])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522cb46b95854002b8f304364d545e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=144.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 127/144 (88.19444444444444%)\n",
      "\n",
      "\n",
      "C-SCNN - Subject: s10\n",
      "INPUT SHAPE:  torch.Size([720, 8, 220, 1])\n",
      "LABEL SHAPE:  torch.Size([720, 12])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c993e9094b7474ca6aabe6be138dcf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=144.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 101/144 (70.13888888888889%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sinabs.from_torch import from_model\n",
    "from bcilib.ssvep_utils_pytorch import CNN, RasterizeSlice, CustomTensorDataset, lam, div\n",
    "c_scnn_acc_list = []\n",
    "\n",
    "\n",
    "print(\"Lam: {} | Div: {}\".format(lam, div))\n",
    "for subject, i in zip(ccnn_training_data.keys(), range(len(ccnn_training_data))):\n",
    "    cnn_model = torch.load(\"models/cnn-s{}.h5\".format(i))\n",
    "    sinabs_model = from_model(\n",
    "        cnn_model,\n",
    "        input_shape = input_shape,\n",
    "        add_spiking_output = True,\n",
    "        synops = True\n",
    "    )\n",
    "    \n",
    "    sinabs_model.to(torch.device(\"cpu\"))\n",
    "    sinabs_model.float()\n",
    "    \n",
    "    print(f'\\nC-SCNN - Subject: {subject}')\n",
    "    test_data = ccnn_training_data[subject]['train_data']\n",
    "    labels = ccnn_training_data[subject]['label']\n",
    "    \n",
    "#     labels = np.argmax(labels, axis=1)\n",
    "    \n",
    "     # transform to torch tensor\n",
    "    tensor_x = torch.from_numpy(test_data).float()\n",
    "    tensor_y = torch.from_numpy(labels.astype(int))\n",
    "    \n",
    "    print(\"INPUT SHAPE: \", tensor_x.shape)\n",
    "    print(\"LABEL SHAPE: \", tensor_y.shape)\n",
    "    \n",
    "    tensor_dataset = CustomTensorDataset(tensor_x, tensor_y, transform = RasterizeSlice())\n",
    "    \n",
    "    # frame_dataset = ShapesNpzDataset(\"/home/nogay/Desktop/frame_dataset/dataset.npz\", target_transform=int)\n",
    "    train_size = int(0.6 * len(tensor_dataset))\n",
    "    val_size = int(0.2 * len(tensor_dataset))\n",
    "    test_size = len(tensor_dataset) - train_size - val_size\n",
    "    \n",
    "    train_dataset, val_dataset, test_dataset = random_split(\n",
    "        tensor_dataset,\n",
    "        [train_size, val_size, test_size],\n",
    "        generator=torch.Generator().manual_seed(42)\n",
    "    )\n",
    "    \n",
    "    dataloader_train = DataLoader(train_dataset, shuffle=True, num_workers=4, batch_size=1)\n",
    "    dataloader_val = DataLoader(val_dataset, shuffle=False, num_workers=4, batch_size=1)\n",
    "    dataloader_test = DataLoader(test_dataset, shuffle=False, num_workers=4, batch_size=1)\n",
    "    \n",
    "    early_stopping = EarlyStopping('val_loss', patience=10, mode='min')\n",
    "#     trainer = pl.Trainer(gpus=1, \n",
    "#                          max_epochs=200, \n",
    "#                          enable_pl_optimizer=True,\n",
    "#                          callbacks=[early_stopping])\n",
    "    \n",
    "    #trainer.fit(model, dataloader_train, val_dataloaders=dataloader_val)\n",
    "    c_scnn_acc_list.append(test(sinabs_model, dataloader_test, num_batches=200))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lam:1; div:12\n",
      "0.4930555555555556\n",
      "0.1875\n",
      "0.75\n",
      "0.8888888888888888\n",
      "0.8958333333333334\n",
      "0.9097222222222222\n",
      "0.6597222222222222\n",
      "0.9861111111111112\n",
      "0.8819444444444444\n",
      "0.7013888888888888\n",
      "\n",
      "Overall: 0.7354166666666668\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "from pprint import pprint\n",
    "\n",
    "print(\"lam:{}; div:{}\".format(lam, div))\n",
    "for result in c_scnn_acc_list:\n",
    "    print(result)\n",
    "    \n",
    "print(\"\\nOverall: {}\".format(reduce(lambda x, y: x + y, c_scnn_acc_list) / len(c_scnn_acc_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    from bcilib.ssvep_utils_pytorch import CNN, RasterizeSlice, CustomTensorDataset, lam, div\n",
    "    import matplotlib.pyplot as plt\n",
    "    for subject in ccnn_training_data.keys():\n",
    "        print(f'\\nC-SCNN - Subject: {subject}')\n",
    "        test_data = ccnn_training_data[subject]['train_data']\n",
    "        labels = ccnn_training_data[subject]['label']\n",
    "\n",
    "    #     labels = np.argmax(labels, axis=1)\n",
    "\n",
    "         # transform to torch tensor\n",
    "        tensor_x = torch.from_numpy(test_data).float()\n",
    "        tensor_y = torch.from_numpy(labels.astype(int))\n",
    "\n",
    "        tensor_dataset = CustomTensorDataset(tensor_x, tensor_y, transform = RasterizeSlice())\n",
    "        dataloader = DataLoader(tensor_dataset, shuffle=True, num_workers=4, batch_size=1)\n",
    "\n",
    "        data_point_count = 0\n",
    "        total_mean = 0\n",
    "\n",
    "        for d in dataloader:\n",
    "            print(d[0].shape)\n",
    "            data_point_count += 1\n",
    "            total_mean += d[0].mean()\n",
    "            # Label\n",
    "            # print(d[1].shape)\n",
    "\n",
    "            s_data = np.zeros((8, 220))\n",
    "\n",
    "            for j in range(d[0].shape[2]):\n",
    "                for i in range(d[0].shape[3]):\n",
    "                    for k in range(d[0].shape[1]):\n",
    "                        if d[0][0,k,j,i,0] == 1:\n",
    "                            s_data[j, i] += 1\n",
    "            statistics = \"min:{}, mean:{:.2f}, max:{}\".format(s_data.min(), s_data.mean(), s_data.max())\n",
    "            print(statistics)\n",
    "            fig, ax = plt.subplots()\n",
    "            # Setting the labels of x axis.\n",
    "            # set the xticks as student-names\n",
    "            # rotate the labels by 90 degree to fit the names\n",
    "            plt.xticks(ticks=np.arange(221),rotation=90)\n",
    "            # Setting the labels of y axis.\n",
    "            # set the xticks as subject-names\n",
    "            plt.yticks(ticks=np.arange(9))\n",
    "            # use the imshow function to generate a heatmap\n",
    "            # cmap parameter gives color to the graph\n",
    "            # setting the interpolation will lead to different types of graphs\n",
    "            # plt.imshow(s_data, cmap='cool',interpolation=\"nearest\")\n",
    "            cmap = plt.cm.jet\n",
    "            norm = plt.Normalize(vmin=s_data.min(), vmax=s_data.max())\n",
    "            image = cmap(norm(s_data))\n",
    "            ax.imshow(s_data, cmap=cmap, interpolation=\"none\")\n",
    "            fig.savefig(\"docs/heatmap-poisson/{}-{}--l:{},d:{}--{}.png\".format(subject, data_point_count - 1, lam, div, statistics), dpi=600, bbox_inches=\"tight\")\n",
    "            plt.show()\n",
    "\n",
    "        print(\"Spike ration: \", total_mean / data_point_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
