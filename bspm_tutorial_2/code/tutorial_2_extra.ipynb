{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the extra work on improving classification performance. The work and why we do that work is explained in the tutorial 2 original notebook, thus commentation will not commence in this one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ../BSPM/data/calibration.fdt\n",
      "Reading 0 ... 248153  =      0.000 ...   969.348 secs...\n",
      "Used Annotations descriptions: ['R  1', 'R  2', 'R  3', 'S  1', 'S  2', 'S  3', 'S  4', 'S  5', 'S  7', 'S  8', 'S  9', 'empty']\n",
      "190 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 190 events and 33 original time points ...\n",
      "0 bad epochs dropped\n",
      "110 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 110 events and 33 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "\n",
    "calibration_path = \"../BSPM/data/calibration.set\"\n",
    "eeg = mne.io.read_raw_eeglab(calibration_path,preload=True)\n",
    "data, times = eeg[:, :]\n",
    "eeg.resample(eeg.info['sfreq']/8) # Downsample the data by 8.\n",
    "channel_list = ['Fz', 'FC1', 'CP1', 'CP2', 'Cz', 'C4', 'FC2']\n",
    "eeg.pick_channels(channel_list)\n",
    "(events_from_annot,event_dict) = mne.events_from_annotations(eeg)\n",
    "epochs_noError = mne.Epochs(eeg,events_from_annot,tmin=-0.2,tmax=0.8,event_id=7,preload=True) # S 4\n",
    "epochs_Error = mne.Epochs(eeg,events_from_annot,tmin=-0.2,tmax=0.8,event_id=8,preload=True) # S 5\n",
    "noError_data = epochs_noError.get_data()\n",
    "error_data = epochs_Error.get_data()\n",
    "noError_label = np.ones(190)\n",
    "error_label = np.ones(110)*-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels and epoch data have been generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get time index in between 0.2 and 0.6\n",
    "noError_data = noError_data[:,:,12:26]\n",
    "error_data = error_data[:,:,12:26]\n",
    "noError_data = noError_data.reshape(190,len(eeg.ch_names)*noError_data.shape[2])\n",
    "error_data = error_data.reshape(110,len(eeg.ch_names)*error_data.shape[2])\n",
    "# Merge data\n",
    "all_data = np.concatenate((noError_data,error_data),axis=0)\n",
    "all_labels = np.concatenate((noError_label,error_label),axis=0)\n",
    "# Min max scaling\n",
    "for i in range(all_data.shape[1]):\n",
    "    all_data[:,i] = (all_data[:,i] - all_data[:,i].min()) / (all_data[:,i].max() - all_data[:,i].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data and labels are ready for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score is: 0.8666666666666667\n",
      "Score is: 0.9\n",
      "Score is: 0.9333333333333333\n",
      "Score is: 0.8\n",
      "Score is: 1.0\n",
      "Score is: 0.8666666666666667\n",
      "Score is: 0.9\n",
      "Score is: 0.9666666666666667\n",
      "Score is: 0.9\n",
      "Score is: 0.8333333333333334\n",
      "Mean score is: 0.8966666666666668\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "kf.get_n_splits(X=all_data,y=all_labels)\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "general_score = 0.0\n",
    "for train_index, test_index in kf.split(all_data):\n",
    "    clf = LinearDiscriminantAnalysis(solver='lsqr',shrinkage=0.4)\n",
    "    clf.fit(all_data[train_index], all_labels[train_index])\n",
    "    score = clf.score(all_data[test_index], all_labels[test_index])\n",
    "    general_score += score\n",
    "    print(\"Score is: \" + str(score))\n",
    "print(\"Mean score is: \" +str(general_score/10.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try different classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score is: 0.8333333333333334\n",
      "Score is: 0.9666666666666667\n",
      "Score is: 0.8666666666666667\n",
      "Score is: 0.8666666666666667\n",
      "Score is: 0.8666666666666667\n",
      "Score is: 0.8666666666666667\n",
      "Score is: 0.9666666666666667\n",
      "Score is: 0.8333333333333334\n",
      "Score is: 1.0\n",
      "Score is: 0.9333333333333333\n",
      "Mean score is: 0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "general_score = 0.0\n",
    "for train_index, test_index in kf.split(all_data):\n",
    "    clf = make_pipeline(StandardScaler(), SVC(kernel='rbf',gamma='auto'))\n",
    "    clf.fit(all_data[train_index], all_labels[train_index])\n",
    "    score = clf.score(all_data[test_index], all_labels[test_index])\n",
    "    general_score += score\n",
    "    print(\"Score is: \" + str(score))\n",
    "print(\"Mean score is: \" +str(general_score/10.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the same transformations to the recall.set and generate vector output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ../BSPM/data/recall.fdt\n",
      "Reading 0 ... 268019  =      0.000 ...  1046.949 secs...\n",
      "Used Annotations descriptions: ['R  1', 'R  2', 'R  3', 'S  1', 'S  2', 'S  3', 'S  6', 'S  7', 'S  8', 'S  9', 'empty']\n",
      "{'R  1': 1, 'R  2': 2, 'R  3': 3, 'S  1': 4, 'S  2': 5, 'S  3': 6, 'S  6': 7, 'S  7': 8, 'S  8': 9, 'S  9': 10, 'empty': 11}\n",
      "300 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "Loading data for 300 events and 33 original time points ...\n",
      "0 bad epochs dropped\n",
      "(300, 98)\n"
     ]
    }
   ],
   "source": [
    "recall_path = \"../BSPM/data/recall.set\"\n",
    "eeg_recall = mne.io.read_raw_eeglab(recall_path,preload=True)\n",
    "data, times = eeg_recall[:, :]\n",
    "eeg_recall.resample(eeg_recall.info['sfreq']/8) # Downsample the data by 8.\n",
    "channel_list = ['Fz', 'FC1', 'CP1', 'CP2', 'Cz', 'C4', 'FC2']\n",
    "eeg_recall.pick_channels(channel_list)\n",
    "(events_from_annot,event_dict) = mne.events_from_annotations(eeg_recall)\n",
    "print(event_dict)\n",
    "#We require S 6: 7\n",
    "#7 is the event id with which we need to epoch from\n",
    "epochs_s6 = mne.Epochs(eeg_recall,events_from_annot,tmin=-0.2,tmax=0.8,event_id=7,preload=True, reject_by_annotation=False) # S 6\n",
    "epochs_data = epochs_s6.get_data()\n",
    "# Get the data between 0.2 and 0.6 seconds\n",
    "epochs_data = epochs_data[:,:,12:26]\n",
    "epochs_data = epochs_data.reshape(300,len(eeg_recall.ch_names)*epochs_data.shape[2])\n",
    "print(epochs_data.shape)\n",
    "#Min Max Scaling on the epochs on recall.set\n",
    "for i in range(epochs_data.shape[1]):\n",
    "    epochs_data[:,i] = (epochs_data[:,i] - epochs_data[:,i].min()) / (epochs_data[:,i].max() - epochs_data[:,i].min())\n",
    "#Train a ShrinkLDA classifier on calibration.set\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "clf = LinearDiscriminantAnalysis(solver='lsqr',shrinkage=0.4)\n",
    "clf.fit(all_data, all_labels)\n",
    "predicted = clf.predict(epochs_data)\n",
    "import scipy.io as sio\n",
    "sio.savemat('./lda_extra.mat', {'vector_output': predicted})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
