{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "import numpy as np\n",
    "import numpy.matlib as npm\n",
    "# import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import optimizers\n",
    "from keras.losses import categorical_crossentropy\n",
    "\n",
    "from bcilib.ssvep_utils_pytorch import CNN, RasterizeSlice, CustomTensorDataset\n",
    "from bcilib import ssvep_utils as su \n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "# from snnlib import snn_utils\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (8, 220, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(features_data):\n",
    "    features_data = np.reshape(features_data, (features_data.shape[0], features_data.shape[1], \n",
    "                                               features_data.shape[2], \n",
    "                                               features_data.shape[3]*features_data.shape[4]))\n",
    "    train_data = features_data[:, :, 0, :].T\n",
    "    for target in range(1, features_data.shape[2]):\n",
    "        train_data = np.vstack([train_data, np.squeeze(features_data[:, :, target, :]).T])\n",
    "\n",
    "    train_data = np.reshape(train_data, (train_data.shape[0], train_data.shape[1], \n",
    "                                         train_data.shape[2], 1))\n",
    "    total_epochs_per_class = features_data.shape[3]\n",
    "    features_data = []\n",
    "    class_labels = np.arange(CNN_PARAMS['num_classes'])\n",
    "    labels = (npm.repmat(class_labels, total_epochs_per_class, 1).T).ravel()\n",
    "    labels = to_categorical(labels)\n",
    "    \n",
    "    return train_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.abspath('data/original')\n",
    "\n",
    "CNN_PARAMS = {\n",
    "    'batch_size': 64,\n",
    "    'epochs': 50,\n",
    "    'droprate': 0.25,\n",
    "    'learning_rate': 0.001,\n",
    "    'lr_decay': 0.0,\n",
    "    'l2_lambda': 0.0001,\n",
    "    'momentum': 0.9,\n",
    "    'kernel_f': 10,\n",
    "    'n_ch': 8,\n",
    "    'num_classes': 12\n",
    "}\n",
    "\n",
    "FFT_PARAMS = {\n",
    "    'resolution': 0.2930,\n",
    "    'start_frequency': 3.0,\n",
    "    'end_frequency': 35.0,\n",
    "    'sampling_rate': 256\n",
    "}\n",
    "\n",
    "window_len = 1\n",
    "shift_len = 1\n",
    "    \n",
    "all_acc = np.zeros((10, 1))\n",
    "\n",
    "magnitude_spectrum_features = dict()\n",
    "complex_spectrum_features = dict()\n",
    "\n",
    "mcnn_training_data = dict()\n",
    "ccnn_training_data = dict()\n",
    "\n",
    "mcnn_results = dict()\n",
    "ccnn_results = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_segmented_data = dict()\n",
    "for subject in range(0, 10):\n",
    "    dataset = sio.loadmat(f'{data_path}/s{subject+1}.mat')\n",
    "    eeg = np.array(dataset['eeg'], dtype='float32')\n",
    "    \n",
    "    CNN_PARAMS['num_classes'] = eeg.shape[0]\n",
    "    CNN_PARAMS['n_ch'] = eeg.shape[1]\n",
    "    total_trial_len = eeg.shape[2]\n",
    "    num_trials = eeg.shape[3]\n",
    "    sample_rate = 256\n",
    "\n",
    "    filtered_data = su.get_filtered_eeg(eeg, 6, 80, 4, sample_rate)\n",
    "    all_segmented_data[f's{subject+1}'] = su.get_segmented_epochs(filtered_data, window_len, \n",
    "                                                                  shift_len, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in all_segmented_data.keys():\n",
    "    complex_spectrum_features[subject] = su.complex_spectrum_features(all_segmented_data[subject], \n",
    "                                                                      FFT_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.453436744813788\n",
      "-4.542808724004553\n",
      "1371913.8662493997\n",
      "1373.4602953441113\n",
      "\n",
      "4.697890353148152\n",
      "-5.587120200892877\n",
      "1320966.1341687553\n",
      "919.1486950344613\n",
      "\n",
      "4.24294748232967\n",
      "-3.9931721341508273\n",
      "1410264.9429553908\n",
      "1789.9135828709188\n",
      "\n",
      "6.390093494479364\n",
      "-7.7297572992609656\n",
      "1227869.4496460753\n",
      "355.23003409219797\n",
      "\n",
      "21.082749462733876\n",
      "-18.468665927927102\n",
      "1077784.5713728983\n",
      "16.162699947894495\n",
      "\n",
      "6.618154987289777\n",
      "-5.988042252342181\n",
      "1257355.231914684\n",
      "499.1691147218926\n",
      "\n",
      "4.193549156789444\n",
      "-4.533442971943087\n",
      "1384656.1550238773\n",
      "1504.5486911991609\n",
      "\n",
      "4.8637124388793245\n",
      "-5.111515517334839\n",
      "1331901.6618140617\n",
      "1007.468584966449\n",
      "\n",
      "4.7738970955208275\n",
      "-4.780804938509801\n",
      "1347989.4343764812\n",
      "1146.4326759918458\n",
      "\n",
      "6.531397488715976\n",
      "-6.482075939864547\n",
      "1248698.7994694596\n",
      "453.75383755283235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for subject in all_segmented_data.keys():\n",
    "#    mcnn_training_data[subject] = dict()\n",
    "    ccnn_training_data[subject] = dict()\n",
    "#     train_data, labels = get_training_data(magnitude_spectrum_features[subject])\n",
    "#     mcnn_training_data[subject]['train_data'] = train_data\n",
    "#     mcnn_training_data[subject]['label'] = labels\n",
    "    \n",
    "    train_data, labels = get_training_data(complex_spectrum_features[subject])\n",
    "    \n",
    "    print(train_data.max())\n",
    "    print(train_data.min())\n",
    "    \n",
    "    train_data = np.power(((train_data - train_data.min() + 1) / (train_data.max() - train_data.min())) * 100, 3)\n",
    "    \n",
    "    print(train_data.max())\n",
    "    print(train_data.min())\n",
    "    print()\n",
    "    \n",
    "    ccnn_training_data[subject]['train_data'] = train_data\n",
    "    ccnn_training_data[subject]['label'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_loader, num_batches=None):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    batch_count = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # model.spiking_model.network[0].weight *= 10\n",
    "        \n",
    "        # Iterate over data\n",
    "        pbar = tqdm.notebook.tqdm(data_loader)\n",
    "        for data, target in pbar:\n",
    "            #if data_loader.dataset.spiking:\n",
    "            if data_loader.dataset:\n",
    "                if len(data.size()) > 4:\n",
    "                    warnings.warn(\"Warning: Batch size needs to be 1, only first sample used.\", stacklevel=2)\n",
    "                    data = data[0]\n",
    "                    target = target[0]\n",
    "            output = model(data)\n",
    "            #print(output)\n",
    "            #if data_loader.dataset.spiking:\n",
    "            if data_loader.dataset:\n",
    "                output = output.sum(0).squeeze().unsqueeze(0)\n",
    "                target = target.unsqueeze(0)\n",
    "            \n",
    "            # get the index of the max log-probability\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            # Compute the total correct predictions\n",
    "            correct += target[0][pred.item()].item() == 1\n",
    "            \n",
    "            batch_count += 1\n",
    "            if (batch_count*data_loader.batch_size)%500 == 0:\n",
    "                pbar.set_postfix({\"Accuracy\" : correct/(batch_count*data_loader.batch_size)})\n",
    "            if num_batches:\n",
    "                if num_batches <= batch_count: break;\n",
    "\n",
    "    # Total samples:\n",
    "    num_data = (batch_count*data_loader.batch_size)\n",
    "\n",
    "    print(f'Test set: Accuracy: {correct}/{num_data} ({100. * correct / num_data}%)\\n'.format(correct, num_data,\n",
    "        ))\n",
    "    return correct / num_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lam: 1 | Div: 12\n",
      "\n",
      "C-SCNN - Subject: s1\n",
      "INPUT SHAPE:  torch.Size([720, 8, 220, 1])\n",
      "LABEL SHAPE:  torch.Size([720, 12])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fc8077f20a446869da339629347719c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=144.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 74/144 (51.388888888888886%)\n",
      "\n",
      "\n",
      "C-SCNN - Subject: s2\n",
      "INPUT SHAPE:  torch.Size([720, 8, 220, 1])\n",
      "LABEL SHAPE:  torch.Size([720, 12])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd29a7accad496c8bdc8ce5a0ce6b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=144.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 48/144 (33.333333333333336%)\n",
      "\n",
      "\n",
      "C-SCNN - Subject: s3\n",
      "INPUT SHAPE:  torch.Size([720, 8, 220, 1])\n",
      "LABEL SHAPE:  torch.Size([720, 12])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d019b83b702446c691c699e4216ead2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=144.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 126/144 (87.5%)\n",
      "\n",
      "\n",
      "C-SCNN - Subject: s4\n",
      "INPUT SHAPE:  torch.Size([720, 8, 220, 1])\n",
      "LABEL SHAPE:  torch.Size([720, 12])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd465744780d443d9dfabbb3df2c91b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=144.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 140/144 (97.22222222222223%)\n",
      "\n",
      "\n",
      "C-SCNN - Subject: s5\n",
      "INPUT SHAPE:  torch.Size([720, 8, 220, 1])\n",
      "LABEL SHAPE:  torch.Size([720, 12])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c43c6a3e2064893a6412dbaa8ae35ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=144.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 143/144 (99.30555555555556%)\n",
      "\n",
      "\n",
      "C-SCNN - Subject: s6\n",
      "INPUT SHAPE:  torch.Size([720, 8, 220, 1])\n",
      "LABEL SHAPE:  torch.Size([720, 12])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aedebfdf3f8742bcac7fcc46cc288134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=144.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 140/144 (97.22222222222223%)\n",
      "\n",
      "\n",
      "C-SCNN - Subject: s7\n",
      "INPUT SHAPE:  torch.Size([720, 8, 220, 1])\n",
      "LABEL SHAPE:  torch.Size([720, 12])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e5d90e6436409a85c77ea14ef4faab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=144.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 104/144 (72.22222222222223%)\n",
      "\n",
      "\n",
      "C-SCNN - Subject: s8\n",
      "INPUT SHAPE:  torch.Size([720, 8, 220, 1])\n",
      "LABEL SHAPE:  torch.Size([720, 12])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ade104ad434937a5a2ec720bb81d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=144.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 141/144 (97.91666666666667%)\n",
      "\n",
      "\n",
      "C-SCNN - Subject: s9\n",
      "INPUT SHAPE:  torch.Size([720, 8, 220, 1])\n",
      "LABEL SHAPE:  torch.Size([720, 12])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab442fd55dc43cf8e6aff8526124b9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=144.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 134/144 (93.05555555555556%)\n",
      "\n",
      "\n",
      "C-SCNN - Subject: s10\n",
      "INPUT SHAPE:  torch.Size([720, 8, 220, 1])\n",
      "LABEL SHAPE:  torch.Size([720, 12])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4d34a20b06471ca94e816223f77a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=144.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 117/144 (81.25%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sinabs.from_torch import from_model\n",
    "from bcilib.ssvep_utils_pytorch import CNN, RasterizeSlice, CustomTensorDataset, lam, div\n",
    "c_scnn_acc_list = []\n",
    "\n",
    "\n",
    "print(\"Lam: {} | Div: {}\".format(lam, div))\n",
    "for subject, i in zip(ccnn_training_data.keys(), range(len(ccnn_training_data))):\n",
    "    cnn_model = torch.load(\"models/cnn-s{}.h5\".format(i))\n",
    "    sinabs_model = from_model(\n",
    "        cnn_model,\n",
    "        input_shape = input_shape,\n",
    "        add_spiking_output = True,\n",
    "        synops = True\n",
    "    )\n",
    "    \n",
    "    sinabs_model.to(torch.device(\"cpu\"))\n",
    "    sinabs_model.float()\n",
    "    \n",
    "    print(f'\\nC-SCNN - Subject: {subject}')\n",
    "    test_data = ccnn_training_data[subject]['train_data']\n",
    "    labels = ccnn_training_data[subject]['label']\n",
    "    \n",
    "#     labels = np.argmax(labels, axis=1)\n",
    "    \n",
    "     # transform to torch tensor\n",
    "    tensor_x = torch.from_numpy(test_data).float()\n",
    "    tensor_y = torch.from_numpy(labels.astype(int))\n",
    "    \n",
    "    print(\"INPUT SHAPE: \", tensor_x.shape)\n",
    "    print(\"LABEL SHAPE: \", tensor_y.shape)\n",
    "    \n",
    "    tensor_dataset = CustomTensorDataset(tensor_x, tensor_y, transform = RasterizeSlice())\n",
    "    \n",
    "    # frame_dataset = ShapesNpzDataset(\"/home/nogay/Desktop/frame_dataset/dataset.npz\", target_transform=int)\n",
    "    train_size = int(0.6 * len(tensor_dataset))\n",
    "    val_size = int(0.2 * len(tensor_dataset))\n",
    "    test_size = len(tensor_dataset) - train_size - val_size\n",
    "    \n",
    "    train_dataset, val_dataset, test_dataset = random_split(\n",
    "        tensor_dataset,\n",
    "        [train_size, val_size, test_size],\n",
    "        generator=torch.Generator().manual_seed(42)\n",
    "    )\n",
    "    \n",
    "    dataloader_train = DataLoader(train_dataset, shuffle=True, num_workers=4, batch_size=1)\n",
    "    dataloader_val = DataLoader(val_dataset, shuffle=False, num_workers=4, batch_size=1)\n",
    "    dataloader_test = DataLoader(test_dataset, shuffle=False, num_workers=4, batch_size=1)\n",
    "    \n",
    "    early_stopping = EarlyStopping('train_loss', patience=10, mode='min')\n",
    "#     trainer = pl.Trainer(gpus=1, \n",
    "#                          max_epochs=200, \n",
    "#                          enable_pl_optimizer=True,\n",
    "#                          callbacks=[early_stopping])\n",
    "    \n",
    "    #trainer.fit(model, dataloader_train, val_dataloaders=dataloader_val)\n",
    "    c_scnn_acc_list.append(test(sinabs_model, dataloader_test, num_batches=200))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lam:1; div:12\n",
      "0.5138888888888888\n",
      "0.3333333333333333\n",
      "0.875\n",
      "0.9722222222222222\n",
      "0.9930555555555556\n",
      "0.9722222222222222\n",
      "0.7222222222222222\n",
      "0.9791666666666666\n",
      "0.9305555555555556\n",
      "0.8125\n",
      "\n",
      "Overall: 0.8104166666666668\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "from pprint import pprint\n",
    "\n",
    "print(\"lam:{}; div:{}\".format(lam, div))\n",
    "for result in c_scnn_acc_list:\n",
    "    print(result)\n",
    "    \n",
    "print(\"\\nOverall: {}\".format(reduce(lambda x, y: x + y, c_scnn_acc_list) / len(c_scnn_acc_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C-SCNN - Subject: s6\n",
      "torch.Size([1, 200, 8, 220, 1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e19bcf5a56dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                         \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                             \u001b[0ms_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mstatistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"min:{}, mean:{:.2f}, max:{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/DSNN/repos/BCI-SNN/miniconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    from bcilib.ssvep_utils_pytorch import CNN, RasterizeSlice, CustomTensorDataset, lam, div\n",
    "    import matplotlib.pyplot as plt\n",
    "    for subject in list(ccnn_training_data.keys())[5:]:\n",
    "        print(f'\\nC-SCNN - Subject: {subject}')\n",
    "        test_data = ccnn_training_data[subject]['train_data']\n",
    "        labels = ccnn_training_data[subject]['label']\n",
    "\n",
    "    #     labels = np.argmax(labels, axis=1)\n",
    "\n",
    "         # transform to torch tensor\n",
    "        tensor_x = torch.from_numpy(test_data).float()\n",
    "        tensor_y = torch.from_numpy(labels.astype(int))\n",
    "\n",
    "        tensor_dataset = CustomTensorDataset(tensor_x, tensor_y, transform = RasterizeSlice())\n",
    "        dataloader = DataLoader(tensor_dataset, shuffle=True, num_workers=4, batch_size=1)\n",
    "\n",
    "        data_point_count = 0\n",
    "        total_mean = 0\n",
    "\n",
    "        for d in dataloader:\n",
    "            print(d[0].shape)\n",
    "            data_point_count += 1\n",
    "            total_mean += d[0].mean()\n",
    "            # Label\n",
    "            # print(d[1].shape)\n",
    "\n",
    "            s_data = np.zeros((8, 220))\n",
    "\n",
    "            for j in range(d[0].shape[2]):\n",
    "                for i in range(d[0].shape[3]):\n",
    "                    for k in range(d[0].shape[1]):\n",
    "                        if d[0][0,k,j,i,0] == 1:\n",
    "                            s_data[j, i] += 1\n",
    "            statistics = \"min:{}, mean:{:.2f}, max:{}\".format(s_data.min(), s_data.mean(), s_data.max())\n",
    "            print(statistics)\n",
    "            fig, ax = plt.subplots()\n",
    "            # Setting the labels of x axis.\n",
    "            # set the xticks as student-names\n",
    "            # rotate the labels by 90 degree to fit the names\n",
    "            plt.xticks(ticks=np.arange(221),rotation=90)\n",
    "            # Setting the labels of y axis.\n",
    "            # set the xticks as subject-names\n",
    "            plt.yticks(ticks=np.arange(9))\n",
    "            # use the imshow function to generate a heatmap\n",
    "            # cmap parameter gives color to the graph\n",
    "            # setting the interpolation will lead to different types of graphs\n",
    "            # plt.imshow(s_data, cmap='cool',interpolation=\"nearest\")\n",
    "            cmap = plt.cm.jet\n",
    "            norm = plt.Normalize(vmin=s_data.min(), vmax=s_data.max())\n",
    "            image = cmap(norm(s_data))\n",
    "            ax.imshow(s_data, cmap=cmap, interpolation=\"none\")\n",
    "            fig.savefig(\"docs/heatmap-poisson/{}-{}--l:{},d:{}--{}.png\".format(subject, data_point_count - 1, lam, div, statistics), dpi=600, bbox_inches=\"tight\")\n",
    "            plt.show()\n",
    "\n",
    "        print(\"Spike ration: \", total_mean / data_point_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
